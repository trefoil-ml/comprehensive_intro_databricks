{"cells":[{"cell_type":"markdown","source":["#Loading data with Azure Databricks"],"metadata":{}},{"cell_type":"markdown","source":["### Import data from a file"],"metadata":{}},{"cell_type":"markdown","source":["In this section you will import a small dataset describing used cars and their price according to various factors."],"metadata":{}},{"cell_type":"markdown","source":["There are multiple ways to make your data available for processing using Azure Databricks, either by connecting to the data source directly or by making a copy of the data into storage managed by Azure Databricks.\n\nAt a high level you can:\n* [Upload small files through the Workspace user interface](https://docs.azuredatabricks.net/user-guide/tables.html#create-table-ui) that are then made available as global tables available across clusters. \n* Connect to remote data sources like Azure Storage blobs, SQL Data Warehouse and Cosmos DB. Once connected, you can copy the data into storage managed by Azure Databricks, if desired.\n\nWhen using Azure Storage blobs, you can:\n* [Access Azure Blob storage directly using the HDFS API](https://docs.azuredatabricks.net/spark/latest/data-sources/azure/azure-storage.html#access-azure-blob-storage-using-the-hdfs-api) and access the data using the WASBS protocol. This approach enables access to all users of the cluster in which access is configured.\n* [Mount Azure Storage blob contains to the Databricks File System (DBFS)](https://docs.azuredatabricks.net/spark/latest/data-sources/azure/azure-storage.html#mount-azure-blob-storage-containers-with-dbfs) and access the data using DBFS file paths (e.g., underneath /mnt). This approach enables access to all users across all clusters in a workspace.\n\nIn this notebook, we will work with a small dataset stored in a CSV file that is available from Azure Storage blobs."],"metadata":{}},{"cell_type":"markdown","source":["First, you will download a copy of the used cars data set. \n\nYou can download this from here:\n[UsedCars.csv](https://databricksdemostore.blob.core.windows.net/data/02.02/UsedCars.csv)"],"metadata":{}},{"cell_type":"markdown","source":["Second, you will upload this CSV file to your Azure Databricks Workspace by following these steps.\n\nOpen a new browser tab and navigate to your workspace.\n\nNavigate to the Data tab and then select + to the right of Tables to create a new table. \n\n![img](https://databricksdemostore.blob.core.windows.net/images/02/data-tab.png)\n\nLeave the Data source set to Upload File. \n\n![img](https://databricksdemostore.blob.core.windows.net/images/02/create-new-table-ui-data-source.png)\n\nSelect browse and then choose your copy of UsedCars.csv\n\n![img](https://databricksdemostore.blob.core.windows.net/images/02/create-new-table-ui-file.png)\n\nYour file will be uploaded. Select Create Table with UI.\n\n![img](https://databricksdemostore.blob.core.windows.net/images/02/create-new-table-ui-file-ready.png)\n\nIn cluster drop-down, select an available cluster, and choose Preview Table. \n\nThen in the Specify Table Attributes, change the table name to **\"usedcars_#####\"** (replace ##### to make the name unique within your environment) and check the box for \"First row is header\". Your preview should look as follows. Observe that the table has the correct header names and that we are defaulting all columns to type STRING.\n\n![img](https://databricksdemostore.blob.core.windows.net/images/02/create-new-table-ui-table-attributes.png)\n\nSelect Create Table. When the Table:usedcars screen appears showing your new table, your data is loaded into a Table and you continue with the next steps in this notebook."],"metadata":{}},{"cell_type":"markdown","source":["### Access imported data"],"metadata":{}},{"cell_type":"markdown","source":["Your data is now available for access using the name \"usedcars\". Run the following SQL query (be sure to update the table name \"usedcars_#####\" with the unique name created during the previous step) to examine the contents:"],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT * FROM usedcars_#####"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Here is a summary of what each of the above columns mean\n\n* Price: Sales price in $\n* Age: Age of car in month\n* KM: Mileage in kilometer\n* Fueltype: Type of fuel used by the car\n* HP: Engine power in Horsepower\n* MetColor: Does the car have metallic paint or not. Binary (0 or 1)\n* Automatic: Is the transmission automatic or not (not meaning manual transmission). Binary (0 or 1)\n* CC: Displacement of the engine in cubic centimeters. (Number of cylinders multiplied by cylinder volume)\n* Doors: Number of doors\n* Weight: Weight in pounds"],"metadata":{}},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM usedcars_#####\")\ndf"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Run the following cell to understand how many rows of data we have in this dataset."],"metadata":{}},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["You are now ready to move to the next step: <a href=\"$./03 Basic EDA with Azure Databricks\">Basic EDA with Azure Databricks</a>"],"metadata":{}}],"metadata":{"name":"02 Loading data with Azure Databricks","notebookId":291050440996155},"nbformat":4,"nbformat_minor":0}
