{"cells":[{"cell_type":"markdown","source":["# Databricks Delta Batch Operations - Upsert\n\nDatabricks&reg; Delta allows you to read, write and query data in data lakes in an efficient manner.\n\n## Datasets Used\nWe will use online retail datasets from\n* `/mnt/training/online_retail` in the demo part and\n* `/mnt/training/structured-streaming/events/` in the exercises"],"metadata":{}},{"cell_type":"markdown","source":["### Getting Started\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["Set up relevant paths."],"metadata":{}},{"cell_type":"code","source":["deltaMiniDataPath = userhome + \"/delta/customer-data-mini/\"\ngenericMiniDataPath = userhome + \"/generic/customer-data-mini/\"\nminiDataInputPath = \"/mnt/training/online_retail/outdoor-products/outdoor-products-mini.csv\""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## UPSERT \n\nLiterally means \"UPdate\" and \"inSERT\". It means to atomically either insert a row, or, if the row already exists, UPDATE the row.\n\nAlter data by changing the values in one of the columns for a specific `CustomerID`.\n\nLet's load the CSV file `../outdoor-products-mini.csv`."],"metadata":{}},{"cell_type":"code","source":["# First, let's load some new data that we want to save to our delta table\nminiDataDF = (spark       \n  .read                                              # Call the read method returning a DataFrame\n  .option(\"inferSchema\",\"true\")                      # Infer schema\n  .option(\"header\",\"true\")                           # File has a header\n  .csv(miniDataInputPath)                            # Path to file\n)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## UPSERT Using Non-Databricks Delta Pipeline\n\nThis feature is not supported in non-Delta pipelines.\n\nTo UPSERT means to \"UPdate\" and \"inSERT\". In other words, UPSERT is not an atomic operation. It is literally TWO operations. \n\nRunning an UPDATE could invalidate data that is accessed by the subsequent INSERT operation."],"metadata":{}},{"cell_type":"markdown","source":["## UPSERT Using Databricks Delta Pipeline\n\nUsing Databricks Delta, however, we can do UPSERTS."],"metadata":{}},{"cell_type":"code","source":["(miniDataDF\n  .write\n  .mode(\"overwrite\")\n  .format(\"delta\")\n  .save(deltaMiniDataPath) \n)\n\nspark.sql(\"\"\"\n    DROP TABLE IF EXISTS customer_data_delta_mini\n  \"\"\")\nspark.sql(\"\"\"\n    CREATE TABLE customer_data_delta_mini\n    USING DELTA \n    LOCATION '{}' \n  \"\"\".format(deltaMiniDataPath))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["List all rows with `CustomerID=20993`."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT * FROM customer_data_delta_mini WHERE CustomerID=20993"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["-sandbox\nForm a new DataFrame where `StockCode` is `99999` for `CustomerID=20993`.\n\nCreate a table `customer_data_delta_to_upsert` that contains this data.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** You need to convert `InvoiceNo` to a `String` because Delta infers types and `InvoiceNo` looks like it should be an integer."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import lit, col\ncustomerSpecificDF = (miniDataDF\n  .filter(\"CustomerID=20993\")\n  .withColumn(\"StockCode\", lit(99999))\n  .withColumn(\"InvoiceNo\", col('InvoiceNo').cast(\"String\")) \n )\n\nspark.sql(\"DROP TABLE IF EXISTS customer_data_delta_to_upsert\")\ncustomerSpecificDF.write.saveAsTable(\"customer_data_delta_to_upsert\")"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Upsert the new data into `customer_data_delta_mini`.\n\nUpsert is done using the `MERGE INTO` syntax."],"metadata":{}},{"cell_type":"code","source":["%sql\nMERGE INTO customer_data_delta_mini\nUSING customer_data_delta_to_upsert\nON customer_data_delta_mini.CustomerID = customer_data_delta_to_upsert.CustomerID\nWHEN MATCHED THEN\n  UPDATE SET\n    customer_data_delta_mini.StockCode = customer_data_delta_to_upsert.StockCode\nWHEN NOT MATCHED\n  THEN INSERT (InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country)\n  VALUES (\n    customer_data_delta_to_upsert.InvoiceNo,\n    customer_data_delta_to_upsert.StockCode, \n    customer_data_delta_to_upsert.Description, \n    customer_data_delta_to_upsert.Quantity, \n    customer_data_delta_to_upsert.InvoiceDate, \n    customer_data_delta_to_upsert.UnitPrice, \n    customer_data_delta_to_upsert.CustomerID, \n    customer_data_delta_to_upsert.Country)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Notice how this data is seamlessly incorporated into `customer_data_delta_mini`."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT * FROM customer_data_delta_mini WHERE CustomerID=20993"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["## Exercise 1\n\nCreate a DataFrame out of the table `demo_iot_data_delta`."],"metadata":{}},{"cell_type":"code","source":["# TODO\nnewDataDF =  spark.sql(\"FILL_IN\")"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# TEST  - Run this cell to test your solution.\nfrom pyspark.sql.types import StructField, StructType, StringType, LongType, DateType, IntegerType\n\nexpectedSchema = StructType([\n   StructField(\"action\",StringType(), True),\n   StructField(\"time\",LongType(), True),\n   StructField(\"date\",DateType(), True),\n   StructField(\"deviceId\",IntegerType(), True),\n])\n\ndbTest(\"Delta-04-schemas\", set(expectedSchema), set(newDataDF.schema))\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["-sandbox\n## Exercise 2\n\nCreate another dataframe where you change`action` to `Close` for `date = '2018-06-01' ` and `deviceId = 485`.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Use `distinct`.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Consider using `selectExpr()`, as we did in [Lesson 3]($./03-Append)."],"metadata":{}},{"cell_type":"code","source":["# TODO\nfrom pyspark.sql.types import LongType\n\nnewDeviceId485DF =  (newDataDF\n .selectExpr(FILL_IN)\n .FILL_IN\n)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\nactionCount = newDeviceId485DF.select(\"Action\").count()\n\ndbTest(\"Delta-L4-actionCount\", 1, actionCount)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["-sandbox\n## Exercise 3\n\nWrite to a new Databricks Delta table that contains just our data to be upserted.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** You can adapt the SQL syntax for the upsert from our demo example, above."],"metadata":{}},{"cell_type":"code","source":["# TODO\nspark.sql(\"FILL_IN\")\nnewDeviceId485DF.write.saveAsTable(\"FILL_IN\")"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ntry:\n  tableExists = (spark.table(\"iot_data_delta_to_upsert\") is not None)\n  count = spark.table(\"iot_data_delta_to_upsert\").count()\nexcept:\n  tableExists = False\n  \ndbTest(\"Delta-04-demoIotTableExists\", True, tableExists)  \ndbTest(\"Delta-04-demoIotTableHasRow\", 1, count)  \n\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["%sql\n--TODO\nMERGE INTO demo_iot_data_delta\nUSING iot_data_delta_to_upsert\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["spark.sql(\"SELECT * FROM demo_iot_data_delta\").count()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["## Exercise 4\n\nCount the number of items in `demo_iot_data_delta` where the `deviceId` is `485` and `action` is `Close`."],"metadata":{}},{"cell_type":"code","source":["# TODO\ncount = spark.sql(\"FILL IN\").collect()[0][0]"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ndbTest(\"Delta-L4-demoiot-count\", 17, count)t\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["## Summary\nIn this Lesson, we used Databricks Delta to UPSERT data into existing Databricks Delta tables."],"metadata":{}},{"cell_type":"markdown","source":["## Review Questions\n\n**Q:** What does it mean to UPSERT?<br>\n**A:** To UPSERT is to either INSERT a row, or if the row already exists, UPDATE the row.\n\n**Q:** What happens if you try to UPSERT in a parquet-based data set?<br>\n**A:** That's not possible due to the schema-on-read paradigm, you will get an error until you refresh the table.\n\n**Q:** What is schema-on-read?<br>\n**A:** It stems from Hive and roughly means: the schema for a data set is unknown until you perform a read operation.\n\n**Q:** How to you perform UPSERT in a Databricks Delta dataset?<br>\n**A:** Using the `MERGE INTO my-table USING data-to-upsert`.\n\n**Q:** What is the caveat to `USING data-to-upsert`?<br>\n**A:** Your source data has ALL the data you want to replace: in other words, you create a new dataframe that has the source data you want to replace in the Databricks Delta table."],"metadata":{}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n\n* <a href=\"https://docs.azuredatabricks.net/delta/delta-batch.html\" target=\"_blank\">Table Batch Read and Writes</a>"],"metadata":{}},{"cell_type":"markdown","source":["## Next Steps\n\nStart the next lesson, [Streaming]($./05-Streaming)."],"metadata":{}}],"metadata":{"name":"04-Upsert","notebookId":291050440994850},"nbformat":4,"nbformat_minor":0}
