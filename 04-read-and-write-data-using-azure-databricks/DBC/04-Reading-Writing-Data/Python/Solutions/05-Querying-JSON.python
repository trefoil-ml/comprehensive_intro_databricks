{"version":"NotebookV1","origId":1745794912677453,"name":"05-Querying-JSON","language":"python","commands":[{"version":"CommandV1","origId":1745794912677454,"guid":"947c0753-ecb3-4b04-a0b3-397684774cf0","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n# Querying JSON & Hierarchical Data with DataFrames\n\nApache Spark&trade; and Azure Databricks&reg; make it easy to work with hierarchical data, such as nested JSON records.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"1c68fdd0-0f98-42f3-b0ba-d97257386fc5"},{"version":"CommandV1","origId":1745794912677455,"guid":"f758f716-3877-4596-8024-a0e57fd142b7","subtype":"command","commandType":"auto","position":3.0,"command":"%md\n### Getting Started\n\nRun the following cell to configure our \"classroom.\"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"0dabeb0f-0b95-4fef-83c0-bc31cdf6f818"},{"version":"CommandV1","origId":1745794912677456,"guid":"7c66bbc6-352a-467d-8e68-08e3bad7ee2f","subtype":"command","commandType":"auto","position":4.0,"command":"%run \"./Includes/Classroom-Setup\"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"7cd9b7e5-74ff-4bf1-8b49-39b6b929ff05"},{"version":"CommandV1","origId":1745794912677457,"guid":"bb07638b-14df-455d-ab41-ec7e226b3f83","subtype":"command","commandType":"auto","position":6.0,"command":"%md\n## Examining the Contents of a JSON file\n\nJSON is a common file format used in big data applications and in data lakes (or large stores of diverse data).  File formats such as JSON arise out of a number of data needs.  For instance, what if:\n<br>\n* Your schema, or the structure of your data, changes over time?\n* You need nested fields like an array with many values or an array of arrays?\n* You don't know how you're going use your data yet, so you don't want to spend time creating relational tables?\n\nThe popularity of JSON is largely due to the fact that JSON allows for nested, flexible schemas.\n\nThis lesson uses the `DatabricksBlog` table, which is backed by JSON file `dbfs:/mnt/training/databricks-blog.json`. If you examine the raw file, notice it contains compact JSON data. There's a single JSON object on each line of the file; each object corresponds to a row in the table. Each row represents a blog post on the <a href=\"https://databricks.com/blog\" target=\"_blank\">Databricks blog</a>, and the table contains all blog posts through August 9, 2017.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"bbfb6909-2848-4262-9874-6de132212b2c"},{"version":"CommandV1","origId":1745794912677458,"guid":"34de273f-8b57-477c-b447-595a0d73b5b6","subtype":"command","commandType":"auto","position":8.0,"command":"%fs head dbfs:/mnt/training/databricks-blog.json","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"31113805-3dac-4ab6-be67-1797574483fd"},{"version":"CommandV1","origId":1745794912677459,"guid":"69ffabc4-aba0-424e-a23c-ea85846d8e11","subtype":"command","commandType":"auto","position":9.0,"command":"%md\nCreate a DataFrame out of the syntax introduced in the previous lesson:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"0b2d8a4d-6a56-472b-b775-f92a75cabe38"},{"version":"CommandV1","origId":1745794912677460,"guid":"bd7e952f-27d5-47e4-9800-96496879c436","subtype":"command","commandType":"auto","position":10.0,"command":"databricksBlogDF = spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"true\").json(\"/mnt/training/databricks-blog.json\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"a7aa99c2-c884-4050-9679-85e1a6b0f470"},{"version":"CommandV1","origId":1745794912677461,"guid":"c7a8dfbf-90a7-4210-8adf-65ff72e24c0d","subtype":"command","commandType":"auto","position":11.0,"command":"%md\nTake a look at the schema by invoking `printSchema` method.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"9a8c0323-e59f-46d8-99c3-c98ee49deb60"},{"version":"CommandV1","origId":1745794912677462,"guid":"d646a09d-9d63-46a6-b5c7-e09e9254865a","subtype":"command","commandType":"auto","position":12.0,"command":"databricksBlogDF.printSchema()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"72e0b5a0-6b74-4984-b6e4-628de54fb3fc"},{"version":"CommandV1","origId":1745794912677463,"guid":"78a3a2cc-2400-4fbf-96b4-7091bc38b452","subtype":"command","commandType":"auto","position":13.0,"command":"%md\nRun a query to view the contents of the table.\n\nNotice:\n* The `authors` column is an array containing one or more author names.\n* The `categories` column is an array of one or more blog post category names.\n* The `dates` column contains nested fields `createdOn`, `publishedOn` and `tz`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"de27d776-febe-4a8b-8d40-7f74bac7aaef"},{"version":"CommandV1","origId":1745794912677464,"guid":"cf73469a-7db8-45af-9d8e-0a8ce50ab709","subtype":"command","commandType":"auto","position":14.0,"command":"display(databricksBlogDF.select(\"authors\",\"categories\",\"dates\",\"content\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"cc43a398-e17a-4883-ae74-8284f015ef4c"},{"version":"CommandV1","origId":1745794912677465,"guid":"2672fafe-b897-41b9-ade8-2ea9a75fb82a","subtype":"command","commandType":"auto","position":15.0,"command":"%md\n## Nested Data\n\nThink of nested data as columns within columns. \n\nFor instance, look at the `dates` column.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"5cfdbac3-662f-499e-acc7-c13fdc485796"},{"version":"CommandV1","origId":1745794912677466,"guid":"84542b04-88ac-4793-a387-bee56fd58add","subtype":"command","commandType":"auto","position":17.0,"command":"datesDF = databricksBlogDF.select(\"dates\")\ndisplay(datesDF)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"694df3f4-e8d7-4ec3-8925-4a80dab0f6a0"},{"version":"CommandV1","origId":1745794912677467,"guid":"7187e55b-44de-4efb-981d-002236701fcf","subtype":"command","commandType":"auto","position":18.0,"command":"%md\nPull out a specific subfield with `.` (object) notation.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"75a89006-47e1-40ee-b728-1cbc152cae7e"},{"version":"CommandV1","origId":1745794912677468,"guid":"51a7b4ab-a6ec-441e-bd62-40b18195b494","subtype":"command","commandType":"auto","position":19.0,"command":"display(databricksBlogDF.select(\"dates.createdOn\", \"dates.publishedOn\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"0dc7e88b-a2a4-4449-824e-b8a847817e1b"},{"version":"CommandV1","origId":1745794912677469,"guid":"179a70ce-6e01-48fd-b67e-d88e580c4990","subtype":"command","commandType":"auto","position":20.0,"command":"%md\nCreate a DataFrame, `databricksBlog2DF` that contains the original columns plus the new `publishedOn` column obtained\nfrom flattening the dates column.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"9b20467b-c110-46fe-b406-752548403011"},{"version":"CommandV1","origId":1745794912677470,"guid":"b05296a7-0d81-40db-9839-ccfda3a525d8","subtype":"command","commandType":"auto","position":21.0,"command":"from pyspark.sql.functions import col\ndatabricksBlog2DF = databricksBlogDF.withColumn(\"publishedOn\",col(\"dates.publishedOn\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"1c924a02-2243-472c-992b-d13d86b2164d"},{"version":"CommandV1","origId":1745794912677471,"guid":"2240f3c7-bd63-46e0-b637-de2f9a57cad1","subtype":"command","commandType":"auto","position":22.0,"command":"%md\nWith this temporary view, apply the `printSchema` method to check its schema and confirm the timestamp conversion.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"85655314-8c14-4e1c-9708-1b18d27a0724"},{"version":"CommandV1","origId":1745794912677472,"guid":"ca395bbd-9153-4621-beb6-ee5c0ef9e877","subtype":"command","commandType":"auto","position":23.0,"command":"databricksBlog2DF.printSchema()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"6b8376e2-a1a0-4313-92ef-e3a995cdb071"},{"version":"CommandV1","origId":1745794912677473,"guid":"b7a2901a-9590-4b68-b3d2-f694520c373f","subtype":"command","commandType":"auto","position":24.0,"command":"%md\nBoth `createdOn` and `publishedOn` are stored as strings.\n\nCast those values to SQL timestamps:\n\nIn this case, use a single `select` method to:\n0. Cast `dates.publishedOn` to a `timestamp` data type\n0. \"Flatten\" the `dates.publishedOn` column to just `publishedOn`","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"5e3205ce-688d-4f7b-970e-28cf5f4288f4"},{"version":"CommandV1","origId":1745794912677474,"guid":"4987e4ef-e726-4a1f-a515-548c73aded88","subtype":"command","commandType":"auto","position":25.0,"command":"from pyspark.sql.functions import date_format\ndisplay(databricksBlogDF.select(\"title\",date_format(\"dates.publishedOn\",\"yyyy-MM-dd\").alias(\"publishedOn\")))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"9709c6f8-40f2-41a2-9e97-51b495d84244"},{"version":"CommandV1","origId":1745794912677475,"guid":"9420525a-682b-4bd4-bb16-f7930eaf10ff","subtype":"command","commandType":"auto","position":26.0,"command":"%md\nCreate another DataFrame, `databricksBlog2DF` that contains the original columns plus the new `publishedOn` column obtained\nfrom flattening the dates column.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"347fb51c-6621-4b43-94d7-4ba8780a6fe4"},{"version":"CommandV1","origId":1745794912677476,"guid":"649fe2d1-8b49-49a8-970b-1f430e14dcdc","subtype":"command","commandType":"auto","position":27.0,"command":"databricksBlog2DF = databricksBlogDF.withColumn(\"publishedOn\", date_format(\"dates.publishedOn\",\"yyyy-MM-dd\")) \ndisplay(databricksBlog2DF)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"1e4b85bd-65fd-4b1e-b458-f02a147fe1e4"},{"version":"CommandV1","origId":1745794912677477,"guid":"89edf1e9-37dd-46cd-8136-b0db17bbd8ad","subtype":"command","commandType":"auto","position":28.0,"command":"%md\nWith this temporary view, apply the `printSchema` method to check its schema and confirm the timestamp conversion.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"2b0ca889-e865-4cfa-b675-2cd851d031b0"},{"version":"CommandV1","origId":1745794912677478,"guid":"b930f6b1-e2b2-410f-8d3d-2475d889aae8","subtype":"command","commandType":"auto","position":29.0,"command":"databricksBlog2DF.printSchema()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"07585b9b-c4cf-4812-962b-493cef66db70"},{"version":"CommandV1","origId":1745794912677479,"guid":"a4b70138-eb94-4368-a730-ec6349726f95","subtype":"command","commandType":"auto","position":30.0,"command":"%md-sandbox\nSince the dates are represented by a `timestamp` data type, we need to convert to a data type that allows `<` and `>`-type comparison operations in order to query for articles within certain date ranges (such as a list of all articles published in 2013). This is accopmplished by using the `to_date` function in Scala or Python.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> See the Spark documentation on <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\" target=\"_blank\">built-in functions</a>, for a long list of date-specific functions.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"f871cd01-85cb-4015-bf3e-4475fac1f500"},{"version":"CommandV1","origId":1745794912677480,"guid":"f9a86ac0-fbd0-45c7-9fdd-8965d4d55411","subtype":"command","commandType":"auto","position":31.0,"command":"from pyspark.sql.functions import to_date, year, col\n          \nresultDF = (databricksBlog2DF.select(\"title\", to_date(col(\"publishedOn\"),\"MMM dd, yyyy\").alias('date'),\"link\") \n  .filter(year(col(\"publishedOn\")) == '2013') \n  .orderBy(col(\"publishedOn\"))\n)\n\ndisplay(resultDF)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"2ceebec4-9d08-4fdd-bcc6-3d887e6ceedb"},{"version":"CommandV1","origId":1745794912677481,"guid":"425a3e59-3889-441c-8a5a-ce723e6aaf66","subtype":"command","commandType":"auto","position":32.0,"command":"%md\n## Array Data\n\nThe DataFrame also contains array columns. \n\nEasily determine the size of each array using the built-in `size(..)` function with array columns.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"41478f14-4773-40c6-8d8c-04470a5a59fb"},{"version":"CommandV1","origId":1745794912677482,"guid":"ae4e0e9c-32f4-400d-bc31-3bd07b9e0c32","subtype":"command","commandType":"auto","position":34.0,"command":"from pyspark.sql.functions import size\ndisplay(databricksBlogDF.select(size(\"authors\"),\"authors\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"5fd9bb79-2808-43d4-84e2-5e06b9614140"},{"version":"CommandV1","origId":1745794912677483,"guid":"871627f4-3c30-41d6-80ef-54e1b36fd40b","subtype":"command","commandType":"auto","position":35.0,"command":"%md\nPull the first element from the array `authors` using an array subscript operator.\n\nFor example, in Scala, the 0th element of array `authors` is `authors(0)`\nwhereas, in Python, the 0th element of `authors` is `authors[0]`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"debd6fea-eefc-452f-b4e6-6a68b48be38e"},{"version":"CommandV1","origId":1745794912677484,"guid":"7e229448-933b-4d97-bf28-16dd82be81ec","subtype":"command","commandType":"auto","position":36.0,"command":"display(databricksBlogDF.select(col(\"authors\")[0].alias(\"primaryAuthor\")))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"36cfe1c7-fdf8-4248-8b79-7e4e75b62b82"},{"version":"CommandV1","origId":1745794912677485,"guid":"840cb143-e115-4ad6-b8ad-7910d09406a1","subtype":"command","commandType":"auto","position":37.0,"command":"%md\n### Explode\n\nThe `explode` method allows you to split an array column into multiple rows, copying all the other columns into each new row. \n\nFor example, split the column `authors` into the column `author`, with one author per row.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"8b05b7c8-94c7-401e-9119-7269538da6c4"},{"version":"CommandV1","origId":1745794912677486,"guid":"3966e540-7102-4eab-983e-e31857c615af","subtype":"command","commandType":"auto","position":39.0,"command":"from pyspark.sql.functions import explode\ndisplay(databricksBlogDF.select(\"title\",\"authors\",explode(col(\"authors\")).alias(\"author\"), \"link\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"dbc461fe-fe5b-40ec-9e5a-8c352e694898"},{"version":"CommandV1","origId":1745794912677487,"guid":"44cfdb27-7ef0-4715-90bf-73c6ab79601e","subtype":"command","commandType":"auto","position":40.0,"command":"%md\nIt's more obvious to restrict the output to articles that have multiple authors, and then sort by the title.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"f5478589-111a-43ad-bdcd-05fbaac11dd8"},{"version":"CommandV1","origId":1745794912677488,"guid":"f39fa898-b01e-48e8-82ea-6f79ce432ffb","subtype":"command","commandType":"auto","position":41.0,"command":"databricksBlog2DF = (databricksBlogDF \n  .select(\"title\",\"authors\",explode(col(\"authors\")).alias(\"author\"), \"link\") \n  .filter(size(col(\"authors\")) > 1) \n  .orderBy(\"title\")\n)\n\ndisplay(databricksBlog2DF)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"78cddac1-7696-4274-9ba9-03602a6c9a37"},{"version":"CommandV1","origId":1745794912677489,"guid":"23f344e7-2649-43c6-b5e4-b6143aab029b","subtype":"command","commandType":"auto","position":42.0,"command":"%md\n## Exercise 1\n\nIdentify all the articles written or co-written by Michael Armbrust.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"22e0936c-34d8-4ba4-9b97-22c544d5bcde"},{"version":"CommandV1","origId":1745794912677490,"guid":"a08f19ca-0f4f-41a7-b1fd-e937518d0746","subtype":"command","commandType":"auto","position":43.0,"command":"%md-sandbox\n### Step 1\n\nStarting with the `databricksBlogDF` DataFrame, create a DataFrame called `articlesByMichaelDF` where:\n0. Michael Armbrust is the author.\n0. The data set contains the column `title` (it may contain others).\n0. It contains only one record per article.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** See the Spark documentation on <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\" target=\"_blank\">built-in functions</a>.  \n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Include the column `authors` in your view to help you debug your solution.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"da248e4d-1087-459e-a7f0-78bb17deeede"},{"version":"CommandV1","origId":1745794912677491,"guid":"a674c758-a497-4b18-a751-7a1dba9e57ad","subtype":"command","commandType":"auto","position":44.0,"command":"# ANSWER\nfrom pyspark.sql.functions import array_contains\narticlesByMichaelDF = databricksBlogDF.select(\"title\").filter(array_contains(\"authors\", \"Michael Armbrust\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"1a136320-f5a9-43b4-89af-6d8c59012423"},{"version":"CommandV1","origId":1745794912677492,"guid":"c8cd9ce2-7544-4479-93eb-8821d482b95e","subtype":"command","commandType":"auto","position":45.0,"command":"# TEST - Run this cell to test your solution.\n\nfrom pyspark.sql import Row\n\nresultsCount = articlesByMichaelDF.count()\ndbTest(\"DF-L5-articlesByMichael-count\", 3, resultsCount)  \n\nresults = articlesByMichaelDF.collect()\n\ndbTest(\"DF-L5-articlesByMichael-0\", Row(title=u'Spark SQL: Manipulating Structured Data Using Apache Spark'), results[0])\ndbTest(\"DF-L5-articlesByMichael-1\", Row(title=u'Exciting Performance Improvements on the Horizon for Spark SQL'), results[1])\ndbTest(\"DF-L5-articlesByMichael-2\", Row(title=u'Spark SQL Data Sources API: Unified Data Access for the Apache Spark Platform'), results[2])\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"e96234c4-9238-4c60-ab66-3609d2c7083a"},{"version":"CommandV1","origId":1745794912677493,"guid":"ce0374a3-c9de-456e-a2b8-6b48e9629add","subtype":"command","commandType":"auto","position":46.0,"command":"%md\n### Step 2\nShow the list of Michael Armbrust's articles in HTML format.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"7774a797-9ebe-4558-9749-488877751715"},{"version":"CommandV1","origId":1745794912677494,"guid":"0f74a615-2de6-4538-92f2-2a20c0464ed7","subtype":"command","commandType":"auto","position":47.0,"command":"# ANSWER\n\ndisplay(articlesByMichaelDF)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"32fbe811-e4b2-4be5-8468-513415ec5344"},{"version":"CommandV1","origId":1745794912677495,"guid":"3a161382-985e-4c7a-9be1-d2c5a377f1d5","subtype":"command","commandType":"auto","position":48.0,"command":"%md\n## Exercise 2\n\nIdentify the complete set of categories used in the Databricks blog articles.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"3a6b7495-354c-4303-bda5-fdf33a8666ec"},{"version":"CommandV1","origId":1745794912677496,"guid":"8aaa4447-5848-42b4-945e-d7c7205ca5c1","subtype":"command","commandType":"auto","position":49.0,"command":"%md\n### Step 1\n\nStarting with the `databricksBlogDF` DataFrame, create another DataFrame called `uniqueCategoriesDF` where:\n0. The data set contains the one column `category` (and no others).\n0. This list of categories should be unique.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"d19fc639-35a7-44f8-a68a-6611821741dd"},{"version":"CommandV1","origId":1745794912677497,"guid":"014ad998-dcd1-4916-9a8d-14aff44514cc","subtype":"command","commandType":"auto","position":50.0,"command":"# ANSWER\nuniqueCategoriesDF = databricksBlogDF.select(explode(col(\"categories\")).alias(\"category\")).orderBy(\"category\").distinct()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"90f3e505-189e-4909-80b7-4027e13b828c"},{"version":"CommandV1","origId":1745794912677498,"guid":"b2ba6e29-0f81-459a-bdd3-2844a85a4369","subtype":"command","commandType":"auto","position":51.0,"command":"# TEST - Run this cell to test your solution.\n\nresultsCount =  uniqueCategoriesDF.count()\n\ndbTest(\"DF-L5-uniqueCategories-count\", 12, resultsCount)\n\nresults = uniqueCategoriesDF.collect()\n\ndbTest(\"DF-L5-uniqueCategories-0\", Row(category=u'Announcements'), results[0])\ndbTest(\"DF-L5-uniqueCategories-1\", Row(category=u'Apache Spark'), results[1])\ndbTest(\"DF-L5-uniqueCategories-2\", Row(category=u'Company Blog'), results[2])\n\ndbTest(\"DF-L5-uniqueCategories-9\", Row(category=u'Platform'), results[9])\ndbTest(\"DF-L5-uniqueCategories-10\", Row(category=u'Product'), results[10])\ndbTest(\"DF-L5-uniqueCategories-11\", Row(category=u'Streaming'), results[11])\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"f2029b42-8f17-4edc-b41f-a7520455bd24"},{"version":"CommandV1","origId":1745794912677499,"guid":"8a6577c9-f40c-4081-93e6-cba2c8d3f297","subtype":"command","commandType":"auto","position":52.0,"command":"%md\n### Step 2\nShow the complete list of categories.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"4198ccd5-cb76-4a6d-8f21-72bf7f3db052"},{"version":"CommandV1","origId":1745794912677500,"guid":"76ddd653-806f-4530-9d48-a113cd633686","subtype":"command","commandType":"auto","position":53.0,"command":"# ANSWER\n\ndisplay(uniqueCategoriesDF.orderBy(\"category\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"cf84ef91-a85b-43ce-9145-b66de2607c12"},{"version":"CommandV1","origId":1745794912677501,"guid":"d96679fe-01ff-46ce-8b75-d5f10da69187","subtype":"command","commandType":"auto","position":54.0,"command":"%md\n## Exercise 3\n\nCount how many times each category is referenced in the Databricks blog.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"7d539cd5-f476-43f2-97f6-583060926541"},{"version":"CommandV1","origId":1745794912677502,"guid":"ce3ffc95-b7ae-43ff-aa19-9f9bb443418b","subtype":"command","commandType":"auto","position":55.0,"command":"%md-sandbox\n### Step 1\n\nStarting with the `databricksBlogDF` DataFrame, create another DataFrame called `totalArticlesByCategoryDF` where:\n0. The new DataFrame contains two columns, `category` and `total`.\n0. The `category` column is a single, distinct category (similar to the last exercise).\n0. The `total` column is the total number of articles in that category.\n0. Order by `category`.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Because articles can be tagged with multiple categories, the sum of the totals adds up to more than the total number of articles.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"6b7be6a1-6ea9-42d2-9ee5-abb9e7d29c07"},{"version":"CommandV1","origId":1745794912677503,"guid":"d9808079-0ef8-4ab4-8a26-5802e47b0812","subtype":"command","commandType":"auto","position":56.0,"command":"# ANSWER\n\nfrom pyspark.sql.functions import count\ntotalArticlesByCategoryDF = (databricksBlogDF \n  .select(explode(col(\"categories\")).alias(\"category\")) \n  .groupBy(\"category\") \n  .agg(count(\"*\").alias(\"total\")) \n  .orderBy(\"category\") \n)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"3cf280d1-2d69-489a-a6cd-faf7359f08b7"},{"version":"CommandV1","origId":1745794912677504,"guid":"74b47ff4-34f9-4376-8a81-05ffff10a99a","subtype":"command","commandType":"auto","position":57.0,"command":"# TEST - Run this cell to test your solution.\n\nresults = totalArticlesByCategoryDF.count()\n\ndbTest(\"DF-L5-articlesByCategory-count\", 12, results)\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"4abc1fc9-ddd6-4d37-bfb3-8b992ba1d230"},{"version":"CommandV1","origId":1745794912677505,"guid":"6f8687e1-b796-4839-90c4-dc1a1c871394","subtype":"command","commandType":"auto","position":58.0,"command":"# TEST - Run this cell to test your solution.\n\nresults = totalArticlesByCategoryDF.collect()\n\ndbTest(\"DF-L5-articlesByCategory-0\", Row(category=u'Announcements', total=72), results[0])\ndbTest(\"DF-L5-articlesByCategory-1\", Row(category=u'Apache Spark', total=132), results[1])\ndbTest(\"DF-L5-articlesByCategory-2\", Row(category=u'Company Blog', total=224), results[2])\n\ndbTest(\"DF-L5-articlesByCategory-9\", Row(category=u'Platform', total=4), results[9])\ndbTest(\"DF-L5-articlesByCategory-10\", Row(category=u'Product', total=83), results[10])\ndbTest(\"DF-L5-articlesByCategory-11\", Row(category=u'Streaming', total=21), results[11])\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"7066d9ef-af0f-4287-8949-b607b98bb852"},{"version":"CommandV1","origId":1745794912677506,"guid":"5e70e0bf-4920-470c-b056-8b78c9754033","subtype":"command","commandType":"auto","position":59.0,"command":"%md\n### Step 2\nDisplay the totals of each category in html format (should be ordered by `category`).","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"f796d664-69ce-4030-8da3-eacb4f272d3a"},{"version":"CommandV1","origId":1745794912677507,"guid":"a79f6d5c-26e4-4e81-a139-c74d03098298","subtype":"command","commandType":"auto","position":60.0,"command":"# ANSWER\ndisplay(totalArticlesByCategoryDF)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"5929d21b-aeb4-4d35-8152-cda71974dd8e"},{"version":"CommandV1","origId":1745794912677508,"guid":"69c58c55-e2ca-428a-a414-4b1d0ba566a2","subtype":"command","commandType":"auto","position":61.0,"command":"%md\n## Summary\n\n* Spark DataFrames allows you to query and manipulate structured and semi-structured data.\n* Spark DataFrames built-in functions provide powerful primitives for querying complex schemas.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"3de4641e-3daf-4500-bee3-b3f3d1064c25"},{"version":"CommandV1","origId":1745794912677509,"guid":"79eb510f-f646-4dad-9c17-a2b7edf49e5c","subtype":"command","commandType":"auto","position":62.0,"command":"%md\n## Review Questions\n**Q:** What is the syntax for accessing nested columns?  \n**A:** Use the dot notation:\n`select(\"dates.publishedOn\")`\n\n**Q:** What is the syntax for accessing the first element in an array?  \n**A:** Use the [subscript] notation: \n`select(\"col(authors)[0]\")`\n\n**Q:** What is the syntax for expanding an array into multiple rows?  \n**A:** Use the explode method:  `select(explode(col(\"authors\")).alias(\"Author\"))`","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"145371b6-932a-494c-8a48-228af90d55b0"},{"version":"CommandV1","origId":1745794912677510,"guid":"f03c6de5-5904-4ab1-857d-2202b0db9b5b","subtype":"command","commandType":"auto","position":63.0,"command":"%md\n## Next Steps\n\nStart the next lesson, [Querying Data Lakes with DataFrames]($./06-Data-Lakes).","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"dc24c4e6-5083-4bb5-9b4c-7993d5d4a1c2"},{"version":"CommandV1","origId":1745794912677511,"guid":"7352f76b-9bdf-4f89-b16c-1e3648a6492c","subtype":"command","commandType":"auto","position":64.0,"command":"%md\n## Additional Topics & Resources\n\n* <a href=\"http://spark.apache.org/docs/latest/sql-programming-guide.html\" target=\"_blank\">Spark SQL, DataFrames and Datasets Guide</a>","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"b9e7089b-9164-463e-8314-8240ed082a1c"}],"dashboards":[],"guid":"6bf3a0c6-9d55-48bd-a711-0bd181024b53","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}}