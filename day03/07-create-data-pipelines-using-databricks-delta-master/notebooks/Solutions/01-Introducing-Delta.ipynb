{"cells":[{"cell_type":"markdown","source":["# Course Overview and Setup\n\nAzure Databricks&reg; provides an Apache Spark&trade; as-a-service workspace environment, making it easy to manage clusters and explore data interactively.\n\n## Databricks Delta\n\nDatabricks&reg; Delta is a transactional storage layer designed specifically to harness the power of Apache Spark and Databricks DBFS. The core abstraction of Databricks Delta is an optimized Spark table that stores your data as Parquet files in DBFS and maintains a transaction log that efficiently tracks changes to the table.\n\n** The course is composed of the following lessons:**  \n1. Course Overview and Setup\n2. Create Table\n3. Append Table\n4. Upsert Table\n5. Streaming \n6. Optimization\n4. Databricks Delta Architecture\n5. Capstone Project"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n# The Challenge with Data Lakes\n### AKA: It's not a Data Lake, it's a Data CESSPOOL\n\nA <b>Data Lake</b>: \n* Is a storage repository that inexpensively stores a vast amount of raw data in its native format.\n* Consists of current and historical data dumps in various formats including XML, JSON, CSV, Parquet, etc.\n* May contain operational relational databases with live transactional data.\n* In effect, it's a dumping ground of amorphous data.\n\nTo extract meaningful information out of a Data Lake, we need to resolve problems like:\n* Schema enforcement when new tables are introduced \n* Table repairs when any new data is inserted into the data lake\n* Frequent refreshes of metadata \n* Bottlenecks of small file sizes for distributed computations\n* Difficulty re-sorting data by an index (i.e. userID) if data is spread across many files and partitioned by i.e. eventTime"],"metadata":{}},{"cell_type":"markdown","source":["# The Solution: Databricks Delta\n\nDatabricks Delta is a Spark table with built-in reliability and performance optimizations.\n\nYou can read and write data stored in Databricks Delta using the same familiar Apache Spark SQL batch and streaming APIs you use to work with Hive tables or DBFS directories. Databricks Delta provides the following functionality:<br><br>\n\n* <b>ACID transactions</b> - Multiple writers can simultaneously modify a data set and see consistent views.\n* <b>DELETES/UPDATES/UPSERTS</b> - Writers can modify a data set without interfering with jobs reading the data set.\n* <b>Automatic file management</b> - Data access speeds up by organizing data into large files that can be read efficiently.\n* <b>Statistics and data skipping</b> - Reads are 10-100x faster when statistics are tracked about the data in each file, allowing Delta to avoid reading irrelevant information."],"metadata":{}},{"cell_type":"markdown","source":["# Up and Running with Databricks\n\nBefore we continue with Databricks Delta, a little digression on setting up your Databricks account. \n\nYou may wish to skip this section if you already have Databricks up and running.\n\nCreate a notebook and Spark cluster."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** This step requires you to navigate Databricks while doing this lesson.  We recommend you <a href=\"\" target=\"_blank\">open a second browser window</a> when navigating Databricks to view these instructions in one window while navigating in the other.\n\n### Step 1\nDatabricks notebooks are backed by clusters, or networked computers that work together to process your data. Create a Spark cluster (*if you already have a running cluster, skip to **Step 2** *):\n1. In your new window, click the **Clusters** button in the sidebar.\n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/create-cluster-4.png\" style=\"height: 200px\"/></div><br/>\n2. Click the **Create Cluster** button.\n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/create-cluster-5.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div><br/>\n3. Name your cluster. Use your name or initials to easily differentiate your cluster from your coworkers.\n4. Select the cluster type. We recommend the latest runtime and Scala **2.11**.\n5. Specify your cluster configuration.\n  * For clusters created on a **Community Edition** shard the default values are sufficient for the remaining fields.\n  * For all other environments, refer to your company's policy on creating and using clusters.</br></br>\n6. Right click on **Cluster** button on left side and open a new tab. Click the **Create Cluster** button.\n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/create-cluster-2.png\" style=\"height: 300px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div>\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Check with your local system administrator to see if there is a recommended default cluster at your company to use for the rest of the class. This could save you some money!"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 2\nCreate a new notebook in your home folder:\n1. Click the **Home** button in the sidebar.\n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/home.png\" style=\"height: 200px\"/></div><br/>\n2. Right-click on your home folder.\n3. Select **Create**.\n4. Select **Notebook**.\n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/create-notebook-1.png\" style=\"height: 150px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div><br/>\n5. Name your notebook `First Notebook`.<br/>\n6. Set the language to **Python**.<br/>\n7. Select the cluster to which to attach this notebook.  \n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> If a cluster is not currently running, this option will not exist.\n8. Click **Create**.\n<div>\n  <div style=\"float:left\"><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/create-notebook-2b.png\" style=\"width:400px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div>\n  <div style=\"float:left\">&nbsp;&nbsp;&nbsp;or&nbsp;&nbsp;&nbsp;</div>\n  <div style=\"float:left\"><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/create-notebook-2.png\" style=\"width:400px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div>\n  <div style=\"clear:both\"></div>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 3\n\nNow that you have a notebook, use it to run code.\n1. In the first cell of your notebook, type `1 + 1`. \n2. Run the cell, click the run icon and select **Run Cell**.\n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/run-notebook-1.png\" style=\"width:600px; margin-bottom:1em; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div>\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> You can also run a cell by typing **Ctrl-Enter**."],"metadata":{}},{"cell_type":"code","source":["1 + 1"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["-sandbox\n\n### Attach and Run\n\nIf your notebook was not previously attached to a cluster you might receive the following prompt: \n<div><img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/run-notebook-2.png\" style=\"margin-bottom:1em; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/></div>\n\nIf you click **Attach and Run**, first make sure you attach to the correct cluster.\n\nIf it is not the correct cluster, click **Cancel** and follow the steps in the the next cell, **Attach & Detach**."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Attach & Detach\n\nIf your notebook is detached you can attach it to another cluster:  \n<img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/attach-to-cluster.png\" style=\"border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/>\n<br/>\n<br/>\n<br/>\nIf your notebook is attached to a cluster you can:\n* Detach your notebook from the cluster\n* Restart the cluster\n* Attach to another cluster\n* Open the Spark UI\n* View the Driver's log files\n\n<img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/detach-from-cluster.png\" style=\"margin-bottom:1em; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa\"/>"],"metadata":{}},{"cell_type":"markdown","source":["## Summary\n* To create a notebook click the down arrow on a folder and select **Create Notebook**.\n* To import notebooks click the down arrow on a folder and select **Import**.\n* To attach to a spark cluster select **Attached/Detached**, directly below the notebook title.\n* Create clusters using the **Clusters** button on the left sidebar."],"metadata":{}},{"cell_type":"markdown","source":["## Review Questions\n\n**Question:** What is Databricks Delta?<br>\n**Answer:** Databricks Delta is a mechanism of effectively managing the flow of data (<b>data pipeline</b>) to and from a <b>Data Lake</b>.\n\n**Question:** What are some of the pain points of existing data pipelines?<br>\n**Answer:** \n* Introduction of new tables requires schema creation \n* Whenever any new data is inserted into the data lake, table repairs are required\n* Metadata must be frequently refreshed\n* Small file sizes become a bottleneck for distributed computations\n* If data is sorted by a particular index (i.e. eventTime), it is very difficult to re-sort the data by a different index (i.e. userID)\n\n**Question:** How do you create a notebook?  \n**Answer:** Sign into Azure Databricks, select the **Home** icon from the sidebar, right-click your home-folder, select **Create**, and then **Notebook**. In the **Create Notebook** dialog, specify the name of your notebook and the default programming language.\n\n**Question:** How do you create a cluster?  \n**Answer:** Select the **Clusters** icon on the sidebar, click the **Create Cluster** button, specify the specific settings for your cluster and then click **Create Cluster**.\n\n**Question:** How do you attach a notebook to a cluster?  \n**Answer:** If you run a command while detached, you may be prompted to connect to a cluster. To connect to a specific cluster, open the cluster menu by clicking the **Attached/Detached** menu item and then selecting your desired cluster."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n## Next Steps\n\nThis course is available in Python and Scala.  Start the next lesson, **02-Create**.\n1. Click the **Home** icon in the left sidebar\n2. Select your home folder\n3. Select the folder **Delta-Version #**\n4. Open the notebook **02-Create** in either the Python or Scala folder\n\n\n<img src=\"https://s3-us-west-2.amazonaws.com/curriculum-release/images/eLearning/Delta/course-import-2.png\" style=\"margin-bottom: 5px; border: 1px solid #aaa; border-radius: 10px 10px 10px 10px; box-shadow: 5px 5px 5px #aaa; width: auto; height: auto; max-height: 350px\"/>"],"metadata":{}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n**Q:** Where can I find documentation on Databricks Delta?  \n**A:** See <a href=\"https://docs.azuredatabricks.net/delta/index.html\" target=\"_blank\">Databricks Delta Guide</a>.\n\n**Q:** Are there additional docs I can reference to find my way around Azure Databricks?  \n**A:** See <a href=\"https://docs.azuredatabricks.net/getting-started/index.html\" target=\"_blank\">Getting Started with Databricks</a>.\n\n**Q:** Where can I learn more about the cluster configuration options?  \n**A:** See <a href=\"https://docs.azuredatabricks.net/user-guide/clusters/index.html\" target=\"_blank\">Spark Clusters on Databricks</a>.\n\n**Q:** Can I import formats other than .dbc files?  \n**A:** Yes, see <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/notebook-manage.html#import-a-notebook\" target=\"_blank\">Importing notebooks</a>."],"metadata":{}}],"metadata":{"name":"01-Introducing-Delta","notebookId":291050440994611},"nbformat":4,"nbformat_minor":0}
