{"version":"NotebookV1","origId":1745794912677093,"name":"05-Querying-JSON","language":"python","commands":[{"version":"CommandV1","origId":1745794912677094,"guid":"7cfe7989-2ea5-4714-98ca-41e8ffdeefe7","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n# Querying JSON & Hierarchical Data with DataFrames\n\nApache Spark&trade; and Azure Databricks&reg; make it easy to work with hierarchical data, such as nested JSON records.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"4503750d-1005-4bd2-a2dc-62c9d65017ec"},{"version":"CommandV1","origId":1745794912677095,"guid":"0dc78a66-bd76-4cef-9112-58900243f233","subtype":"command","commandType":"auto","position":3.0,"command":"%md\n### Getting Started\n\nRun the following cell to configure our \"classroom.\"","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"64c8b961-3022-4541-a3e2-ac00046bc581"},{"version":"CommandV1","origId":1745794912677096,"guid":"7590362c-b79d-41fc-85ed-a868096bed2d","subtype":"command","commandType":"auto","position":4.0,"command":"%run \"./Includes/Classroom-Setup\"","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"2e355540-14e1-40d2-bc77-acf586a13093"},{"version":"CommandV1","origId":1745794912677097,"guid":"cfe48cf0-d8f4-4ccf-95b3-2f95252646fd","subtype":"command","commandType":"auto","position":6.0,"command":"%md\n## Examining the Contents of a JSON file\n\nJSON is a common file format used in big data applications and in data lakes (or large stores of diverse data).  File formats such as JSON arise out of a number of data needs.  For instance, what if:\n<br>\n* Your schema, or the structure of your data, changes over time?\n* You need nested fields like an array with many values or an array of arrays?\n* You don't know how you're going use your data yet, so you don't want to spend time creating relational tables?\n\nThe popularity of JSON is largely due to the fact that JSON allows for nested, flexible schemas.\n\nThis lesson uses the `DatabricksBlog` table, which is backed by JSON file `dbfs:/mnt/training/databricks-blog.json`. If you examine the raw file, notice it contains compact JSON data. There's a single JSON object on each line of the file; each object corresponds to a row in the table. Each row represents a blog post on the <a href=\"https://databricks.com/blog\" target=\"_blank\">Databricks blog</a>, and the table contains all blog posts through August 9, 2017.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"912076c2-1e2d-47ae-a082-650b7fe84403"},{"version":"CommandV1","origId":1745794912677098,"guid":"dc5f2496-7888-48ee-944f-9fea517043ce","subtype":"command","commandType":"auto","position":8.0,"command":"%fs head dbfs:/mnt/training/databricks-blog.json","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985401166,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"ebc7a386-ceff-4ad7-8cff-486f41613c67"},{"version":"CommandV1","origId":1745794912677099,"guid":"64427aee-f566-4c4f-b55e-bbb8e36a48c4","subtype":"command","commandType":"auto","position":9.0,"command":"%md\nCreate a DataFrame out of the syntax introduced in the previous lesson:","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"ff572342-f353-4a11-a7dc-1ace1a136b78"},{"version":"CommandV1","origId":1745794912677100,"guid":"9b4a4f01-4b43-4733-b825-7291b5feac4f","subtype":"command","commandType":"auto","position":10.0,"command":"databricksBlogDF = spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"true\").json(\"/mnt/training/databricks-blog.json\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985426685,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"953fdc42-f112-4ab3-ae9e-048e41948bf2"},{"version":"CommandV1","origId":1745794912677101,"guid":"b7bdc3ef-9cd1-4fa5-84b0-6d69d4376059","subtype":"command","commandType":"auto","position":11.0,"command":"%md\nTake a look at the schema by invoking `printSchema` method.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"6aa145c7-200c-48af-aaae-36eba70a2ae0"},{"version":"CommandV1","origId":1745794912677102,"guid":"36fd023e-f0e8-4e01-83a1-1d3b24e5fc69","subtype":"command","commandType":"auto","position":12.0,"command":"databricksBlogDF.printSchema()","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985437834,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"9ddb994c-0d03-413a-8698-14db037a0b3b"},{"version":"CommandV1","origId":1745794912677103,"guid":"ba1f9914-a020-4d9f-983a-282979f7370c","subtype":"command","commandType":"auto","position":13.0,"command":"%md\nRun a query to view the contents of the table.\n\nNotice:\n* The `authors` column is an array containing one or more author names.\n* The `categories` column is an array of one or more blog post category names.\n* The `dates` column contains nested fields `createdOn`, `publishedOn` and `tz`.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"6cc5e3e1-5b83-46cd-a470-d6a7455456a9"},{"version":"CommandV1","origId":1745794912677104,"guid":"24e9d4f2-33d1-47e3-8982-cb0049a54167","subtype":"command","commandType":"auto","position":14.0,"command":"display(databricksBlogDF.select(\"authors\",\"categories\",\"dates\",\"content\"))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985456310,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"16cceb69-f10e-41bf-b1a8-f84c0a0c7db7"},{"version":"CommandV1","origId":1745794912677105,"guid":"428caa7b-b332-4afe-ab5c-675fd74e2f5f","subtype":"command","commandType":"auto","position":15.0,"command":"%md\n## Nested Data\n\nThink of nested data as columns within columns. \n\nFor instance, look at the `dates` column.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"29dac74c-c574-4fbe-98a5-31d28fb255be"},{"version":"CommandV1","origId":1745794912677106,"guid":"7e52abd9-b0d4-4534-b16b-1d18e62e76cc","subtype":"command","commandType":"auto","position":17.0,"command":"datesDF = databricksBlogDF.select(\"dates\")\ndisplay(datesDF)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985514842,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"9cc8cd56-51a7-412f-b5ee-4890124a9e7d"},{"version":"CommandV1","origId":1745794912677107,"guid":"af40a31d-477d-429e-a18c-e62d0201e6c9","subtype":"command","commandType":"auto","position":18.0,"command":"%md\nPull out a specific subfield with `.` (object) notation.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"18d538cc-27a0-47ed-8680-6e9549b58be8"},{"version":"CommandV1","origId":1745794912677108,"guid":"f8452e09-cd93-4d48-9547-c53e5432f1c3","subtype":"command","commandType":"auto","position":19.0,"command":"display(databricksBlogDF.select(\"dates.createdOn\", \"dates.publishedOn\"))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985541308,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"86e9813b-b023-494d-8678-b8f49d231ef4"},{"version":"CommandV1","origId":1745794912677109,"guid":"9a7a51a9-db65-434b-a00e-251e764de328","subtype":"command","commandType":"auto","position":20.0,"command":"%md\nCreate a DataFrame, `databricksBlog2DF` that contains the original columns plus the new `publishedOn` column obtained\nfrom flattening the dates column.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"75f8b743-f42f-4f5f-9355-ca42121a80a0"},{"version":"CommandV1","origId":1745794912677110,"guid":"b79d50bc-212e-4ab9-b125-4b586a779276","subtype":"command","commandType":"auto","position":21.0,"command":"from pyspark.sql.functions import col\ndatabricksBlog2DF = databricksBlogDF.withColumn(\"publishedOn\",col(\"dates.publishedOn\"))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985569245,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"5fa1c141-a29a-4f41-b660-6a3cb01032b9"},{"version":"CommandV1","origId":1745794912677111,"guid":"b0dd7d38-2e32-44f6-8ae1-cb11f2506123","subtype":"command","commandType":"auto","position":22.0,"command":"%md\nWith this temporary view, apply the `printSchema` method to check its schema and confirm the timestamp conversion.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"98e5bc02-6815-418a-bcb5-88a2e3e09837"},{"version":"CommandV1","origId":1745794912677112,"guid":"adc46d64-eef5-4448-923b-9bd2d81b7ad9","subtype":"command","commandType":"auto","position":23.0,"command":"databricksBlog2DF.printSchema()","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985584560,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"b9c5df5e-a163-4588-b052-b752d471885e"},{"version":"CommandV1","origId":1745794912677113,"guid":"02cc61d1-30e5-46fa-97eb-08ed28512515","subtype":"command","commandType":"auto","position":24.0,"command":"%md\nBoth `createdOn` and `publishedOn` are stored as strings.\n\nCast those values to SQL timestamps:\n\nIn this case, use a single `select` method to:\n0. Cast `dates.publishedOn` to a `timestamp` data type\n0. \"Flatten\" the `dates.publishedOn` column to just `publishedOn`","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"802f9b24-b2ed-4067-b73b-3356dbdfdd9b"},{"version":"CommandV1","origId":1745794912677114,"guid":"3b88097a-fb85-46be-a205-8d4e27d2c5a4","subtype":"command","commandType":"auto","position":25.0,"command":"from pyspark.sql.functions import date_format\ndisplay(databricksBlogDF.select(\"title\",date_format(\"dates.publishedOn\",\"yyyy-MM-dd\").alias(\"publishedOn\")))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985645104,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"294ac185-01c3-4ce8-9ae5-10b27b606851"},{"version":"CommandV1","origId":1745794912677115,"guid":"f0a6e243-7fe5-4664-af19-51ebdf56a2ed","subtype":"command","commandType":"auto","position":26.0,"command":"%md\nCreate another DataFrame, `databricksBlog2DF` that contains the original columns plus the new `publishedOn` column obtained\nfrom flattening the dates column.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"22b7c4fc-48ec-4d8a-afa9-c579687ee39e"},{"version":"CommandV1","origId":1745794912677116,"guid":"d75a0eb2-5d5d-4453-b5b2-b1c59fad5d68","subtype":"command","commandType":"auto","position":27.0,"command":"databricksBlog2DF = databricksBlogDF.withColumn(\"publishedOn\", date_format(\"dates.publishedOn\",\"yyyy-MM-dd\")) \ndisplay(databricksBlog2DF)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985667638,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"02889bed-784e-4526-a6fc-f7ba8b7df1ac"},{"version":"CommandV1","origId":1745794912677117,"guid":"8b9c0121-0f50-468c-b15c-30007182af24","subtype":"command","commandType":"auto","position":28.0,"command":"%md\nWith this temporary view, apply the `printSchema` method to check its schema and confirm the timestamp conversion.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"f801744a-2eef-4174-993a-60192dde49e6"},{"version":"CommandV1","origId":1745794912677118,"guid":"4702ba87-f597-4886-b072-3637aa9c326e","subtype":"command","commandType":"auto","position":29.0,"command":"databricksBlog2DF.printSchema()","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985689262,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"dacafc76-10ad-471e-8569-68f01f9ee1b7"},{"version":"CommandV1","origId":1745794912677119,"guid":"ad9bd33c-6182-4bed-a53e-cb1d793f7c15","subtype":"command","commandType":"auto","position":30.0,"command":"%md-sandbox\nSince the dates are represented by a `timestamp` data type, we need to convert to a data type that allows `<` and `>`-type comparison operations in order to query for articles within certain date ranges (such as a list of all articles published in 2013). This is accopmplished by using the `to_date` function in Scala or Python.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> See the Spark documentation on <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\" target=\"_blank\">built-in functions</a>, for a long list of date-specific functions.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"e232af75-fed5-433b-9a0d-48281d9551f7"},{"version":"CommandV1","origId":1745794912677120,"guid":"25da501c-0b51-4176-8f59-e07ff23955cb","subtype":"command","commandType":"auto","position":31.0,"command":"from pyspark.sql.functions import to_date, year, col\n          \nresultDF = (databricksBlog2DF.select(\"title\", to_date(col(\"publishedOn\"),\"MMM dd, yyyy\").alias('date'),\"link\") \n  .filter(year(col(\"publishedOn\")) == '2013') \n  .orderBy(col(\"publishedOn\"))\n)\n\ndisplay(resultDF)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985806964,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"1778","height":"237","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"e522cc71-96e5-4945-86e7-bd4fc5f9ea14"},{"version":"CommandV1","origId":1745794912677121,"guid":"c904c611-bacf-4024-b684-4b9a784832dd","subtype":"command","commandType":"auto","position":32.0,"command":"%md\n## Array Data\n\nThe DataFrame also contains array columns. \n\nEasily determine the size of each array using the built-in `size(..)` function with array columns.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"e343e8fa-406c-4188-a563-be98b7587b1f"},{"version":"CommandV1","origId":1745794912677122,"guid":"de1422dd-f225-4c5f-85e5-7c93096402a2","subtype":"command","commandType":"auto","position":34.0,"command":"from pyspark.sql.functions import size\ndisplay(databricksBlogDF.select(size(\"authors\"),\"authors\"))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985826475,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"fab56517-f460-4cbb-983e-d6de42b42ffc"},{"version":"CommandV1","origId":1745794912677123,"guid":"01f973d5-0086-4516-9f51-dfd709ae4ce7","subtype":"command","commandType":"auto","position":35.0,"command":"%md\nPull the first element from the array `authors` using an array subscript operator.\n\nFor example, in Scala, the 0th element of array `authors` is `authors(0)`\nwhereas, in Python, the 0th element of `authors` is `authors[0]`.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"5165ae37-39fe-4e74-afd3-7ac61fb558c3"},{"version":"CommandV1","origId":1745794912677124,"guid":"99eeef0f-1aa4-421d-a838-cd56f3b9bae3","subtype":"command","commandType":"auto","position":36.0,"command":"display(databricksBlogDF.select(col(\"authors\")[0].alias(\"primaryAuthor\")))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985879125,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"229daea6-a33d-4e08-9109-3924f9ddb453"},{"version":"CommandV1","origId":1745794912677125,"guid":"3cfd7ffd-1261-4116-a7c2-cb1337b08669","subtype":"command","commandType":"auto","position":37.0,"command":"%md\n### Explode\n\nThe `explode` method allows you to split an array column into multiple rows, copying all the other columns into each new row. \n\nFor example, split the column `authors` into the column `author`, with one author per row.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"1bf6078d-12f3-4dfb-8075-d0e9d41a20da"},{"version":"CommandV1","origId":1745794912677126,"guid":"783adcb3-2a7a-43f4-a26d-e67cdad2d19f","subtype":"command","commandType":"auto","position":39.0,"command":"from pyspark.sql.functions import explode\ndisplay(databricksBlogDF.select(\"title\",\"authors\",explode(col(\"authors\")).alias(\"author\"), \"link\"))","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985915837,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"6c15db88-50bb-4f72-8d17-6fc206a141e6"},{"version":"CommandV1","origId":1745794912677127,"guid":"42f21aa2-f2b3-4e44-9fd5-871e231cf51c","subtype":"command","commandType":"auto","position":40.0,"command":"%md\nIt's more obvious to restrict the output to articles that have multiple authors, and then sort by the title.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"cc718092-19b9-4f9f-ae1b-5fabade725b7"},{"version":"CommandV1","origId":1745794912677128,"guid":"a9b3125b-2478-4ba4-8e05-f2b030619e97","subtype":"command","commandType":"auto","position":41.0,"command":"databricksBlog2DF = (databricksBlogDF \n  .select(\"title\",\"authors\",explode(col(\"authors\")).alias(\"author\"), \"link\") \n  .filter(size(col(\"authors\")) > 1) \n  .orderBy(\"title\")\n)\n\ndisplay(databricksBlog2DF)","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1534985954951,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"lino@solliance.net","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"b6845ba7-ac8d-46bf-ad2b-7c4c7c24f84a"},{"version":"CommandV1","origId":1745794912677129,"guid":"6f20b5c3-02fa-4f6c-b793-1251030e4ef8","subtype":"command","commandType":"auto","position":42.0,"command":"%md\n## Exercise 1\n\nIdentify all the articles written or co-written by Michael Armbrust.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"d7d37aa0-d80a-47e4-8660-1780ca1fd74b"},{"version":"CommandV1","origId":1745794912677130,"guid":"a462e624-3487-427a-95ca-c8a9e955c650","subtype":"command","commandType":"auto","position":43.0,"command":"%md-sandbox\n### Step 1\n\nStarting with the `databricksBlogDF` DataFrame, create a DataFrame called `articlesByMichaelDF` where:\n0. Michael Armbrust is the author.\n0. The data set contains the column `title` (it may contain others).\n0. It contains only one record per article.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** See the Spark documentation on <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\" target=\"_blank\">built-in functions</a>.  \n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Include the column `authors` in your view to help you debug your solution.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"3a805d0d-312e-411b-94a2-babf92655d52"},{"version":"CommandV1","origId":1745794912677131,"guid":"87962377-6d57-4cc7-aa62-9447686c8dc8","subtype":"command","commandType":"auto","position":44.0,"command":"# TODO\nfrom pyspark.sql.functions import array_contains\narticlesByMichaelDF = # FILL_IN","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"2d88be08-7b02-49d3-88a2-a632124bcbbe"},{"version":"CommandV1","origId":1745794912677132,"guid":"4e77489f-b155-4578-a172-6f218867a05c","subtype":"command","commandType":"auto","position":45.0,"command":"# TEST - Run this cell to test your solution.\n\nfrom pyspark.sql import Row\n\nresultsCount = articlesByMichaelDF.count()\ndbTest(\"DF-L5-articlesByMichael-count\", 3, resultsCount)  \n\nresults = articlesByMichaelDF.collect()\n\ndbTest(\"DF-L5-articlesByMichael-0\", Row(title=u'Spark SQL: Manipulating Structured Data Using Apache Spark'), results[0])\ndbTest(\"DF-L5-articlesByMichael-1\", Row(title=u'Exciting Performance Improvements on the Horizon for Spark SQL'), results[1])\ndbTest(\"DF-L5-articlesByMichael-2\", Row(title=u'Spark SQL Data Sources API: Unified Data Access for the Apache Spark Platform'), results[2])\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"dbe3a0f9-2948-4f8e-b03b-72f00a8c6708"},{"version":"CommandV1","origId":1745794912677133,"guid":"47177e53-aec7-42e1-a89d-05e8aead80e8","subtype":"command","commandType":"auto","position":46.0,"command":"%md\n### Step 2\nShow the list of Michael Armbrust's articles in HTML format.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"47ab07d0-7cbd-45e6-b9ac-e3271bd2dabe"},{"version":"CommandV1","origId":1745794912677134,"guid":"ede96933-4341-4b9a-897a-b2d3e5af863f","subtype":"command","commandType":"auto","position":47.0,"command":"%md\n## Exercise 2\n\nIdentify the complete set of categories used in the Databricks blog articles.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"26294039-675c-41e9-96a6-3ff38f742c03"},{"version":"CommandV1","origId":1745794912677135,"guid":"98c7910d-8174-4263-a558-deb719fbd7ff","subtype":"command","commandType":"auto","position":48.0,"command":"%md\n### Step 1\n\nStarting with the `databricksBlogDF` DataFrame, create another DataFrame called `uniqueCategoriesDF` where:\n0. The data set contains the one column `category` (and no others).\n0. This list of categories should be unique.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"41cba434-897d-4693-a45a-d94d0d480d3f"},{"version":"CommandV1","origId":1745794912677136,"guid":"0b9e4db0-c717-4b71-adf0-389a6d5647aa","subtype":"command","commandType":"auto","position":49.0,"command":"# TODO\nuniqueCategoriesDF = # FILL_IN","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"46f46902-817c-465c-a06d-e77ba16ad173"},{"version":"CommandV1","origId":1745794912677137,"guid":"4728a263-4127-4bfe-9b04-0e440289c74e","subtype":"command","commandType":"auto","position":50.0,"command":"# TEST - Run this cell to test your solution.\n\nresultsCount =  uniqueCategoriesDF.count()\n\ndbTest(\"DF-L5-uniqueCategories-count\", 12, resultsCount)\n\nresults = uniqueCategoriesDF.collect()\n\ndbTest(\"DF-L5-uniqueCategories-0\", Row(category=u'Announcements'), results[0])\ndbTest(\"DF-L5-uniqueCategories-1\", Row(category=u'Apache Spark'), results[1])\ndbTest(\"DF-L5-uniqueCategories-2\", Row(category=u'Company Blog'), results[2])\n\ndbTest(\"DF-L5-uniqueCategories-9\", Row(category=u'Platform'), results[9])\ndbTest(\"DF-L5-uniqueCategories-10\", Row(category=u'Product'), results[10])\ndbTest(\"DF-L5-uniqueCategories-11\", Row(category=u'Streaming'), results[11])\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"aa1c9c9e-3957-4938-bd2b-398d127621cc"},{"version":"CommandV1","origId":1745794912677138,"guid":"77496406-434c-451c-b416-ee59759b369e","subtype":"command","commandType":"auto","position":51.0,"command":"%md\n### Step 2\nShow the complete list of categories.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"84b573e1-057b-445a-af16-a155c4804001"},{"version":"CommandV1","origId":1745794912677139,"guid":"fc89b4be-74f8-4072-aabc-5175ff2e11dc","subtype":"command","commandType":"auto","position":52.0,"command":"# TODO\n\nFILL_IN","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"26128c75-b382-49a7-a202-0252dd4f84a0"},{"version":"CommandV1","origId":1745794912677140,"guid":"587a479d-66cd-434b-8721-48c279303412","subtype":"command","commandType":"auto","position":53.0,"command":"%md\n## Exercise 3\n\nCount how many times each category is referenced in the Databricks blog.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"b4731148-746a-45aa-903e-141dd5700fa2"},{"version":"CommandV1","origId":1745794912677141,"guid":"90a265f6-56ea-475d-a16f-4fc6bf35f0d4","subtype":"command","commandType":"auto","position":54.0,"command":"%md-sandbox\n### Step 1\n\nStarting with the `databricksBlogDF` DataFrame, create another DataFrame called `totalArticlesByCategoryDF` where:\n0. The new DataFrame contains two columns, `category` and `total`.\n0. The `category` column is a single, distinct category (similar to the last exercise).\n0. The `total` column is the total number of articles in that category.\n0. Order by `category`.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Because articles can be tagged with multiple categories, the sum of the totals adds up to more than the total number of articles.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"e16d2e9f-9995-477f-90c6-3a80b6adb839"},{"version":"CommandV1","origId":1745794912677142,"guid":"d6e45016-1dba-486c-a5a5-62d9f843a305","subtype":"command","commandType":"auto","position":55.0,"command":"# TODO\n\nfrom pyspark.sql.functions import count\ntotalArticlesByCategoryDF = # FILL_IN","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"2b9ced90-9300-4422-8c90-e45ec9ba13d6"},{"version":"CommandV1","origId":1745794912677143,"guid":"19d5f536-f0af-43fb-b411-705744c9fb7b","subtype":"command","commandType":"auto","position":56.0,"command":"# TEST - Run this cell to test your solution.\n\nresults = totalArticlesByCategoryDF.count()\n\ndbTest(\"DF-L5-articlesByCategory-count\", 12, results)\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"cd0a8863-aa4d-4a5c-83b2-8a28f7ab5f61"},{"version":"CommandV1","origId":1745794912677144,"guid":"d35202af-3fd7-4f1d-99b1-07af1ab96c1f","subtype":"command","commandType":"auto","position":57.0,"command":"# TEST - Run this cell to test your solution.\n\nresults = totalArticlesByCategoryDF.collect()\n\ndbTest(\"DF-L5-articlesByCategory-0\", Row(category=u'Announcements', total=72), results[0])\ndbTest(\"DF-L5-articlesByCategory-1\", Row(category=u'Apache Spark', total=132), results[1])\ndbTest(\"DF-L5-articlesByCategory-2\", Row(category=u'Company Blog', total=224), results[2])\n\ndbTest(\"DF-L5-articlesByCategory-9\", Row(category=u'Platform', total=4), results[9])\ndbTest(\"DF-L5-articlesByCategory-10\", Row(category=u'Product', total=83), results[10])\ndbTest(\"DF-L5-articlesByCategory-11\", Row(category=u'Streaming', total=21), results[11])\n\nprint(\"Tests passed!\")","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"e36bc544-3dd7-42be-ad02-202a41c89998"},{"version":"CommandV1","origId":1745794912677145,"guid":"1172dcb8-aaa1-45d7-916d-7555f6fe4c1a","subtype":"command","commandType":"auto","position":58.0,"command":"%md\n### Step 2\nDisplay the totals of each category in html format (should be ordered by `category`).","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"336c9cbc-816a-4fad-bd69-a31db8fb5958"},{"version":"CommandV1","origId":1745794912677146,"guid":"88a9236b-b918-4e64-90f3-e6c869cee640","subtype":"command","commandType":"auto","position":59.0,"command":"# TODO\n\nFILL_IN","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"047f3840-6993-4fd5-935c-2f212f9f4637"},{"version":"CommandV1","origId":1745794912677147,"guid":"4a0cdc68-5f95-4e5a-b5ac-3de2718b0665","subtype":"command","commandType":"auto","position":60.0,"command":"%md\n## Summary\n\n* Spark DataFrames allows you to query and manipulate structured and semi-structured data.\n* Spark DataFrames built-in functions provide powerful primitives for querying complex schemas.","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"0d78e3dc-329c-46a2-83d8-0cfe259d2ed3"},{"version":"CommandV1","origId":1745794912677148,"guid":"9050dee1-51c5-4413-a437-8a5b09c7d084","subtype":"command","commandType":"auto","position":61.0,"command":"%md\n## Review Questions\n**Q:** What is the syntax for accessing nested columns?  \n**A:** Use the dot notation:\n`select(\"dates.publishedOn\")`\n\n**Q:** What is the syntax for accessing the first element in an array?  \n**A:** Use the [subscript] notation: \n`select(\"col(authors)[0]\")`\n\n**Q:** What is the syntax for expanding an array into multiple rows?  \n**A:** Use the explode method:  `select(explode(col(\"authors\")).alias(\"Author\"))`","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"cad0adf8-3c41-499f-a75e-9887c8286337"},{"version":"CommandV1","origId":1745794912677149,"guid":"5ccace05-606c-4ab5-b85e-4ee639d4c7b8","subtype":"command","commandType":"auto","position":62.0,"command":"%md\n## Next Steps\n\nStart the next lesson, [Querying Data Lakes with DataFrames]($./06-Data-Lakes).","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"bfa18eb1-2448-4a38-95e4-2753ccc1b2c4"},{"version":"CommandV1","origId":1745794912677150,"guid":"f88d53b8-f6c8-428d-b3fe-9ffa71200fdc","subtype":"command","commandType":"auto","position":63.0,"command":"%md\n## Additional Topics & Resources\n\n* <a href=\"http://spark.apache.org/docs/latest/sql-programming-guide.html\" target=\"_blank\">Spark SQL, DataFrames and Datasets Guide</a>","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","latestUserId":"4258953226069350","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"81fc6e00-e9ec-4bcb-b6ed-3d618226054d"}],"dashboards":[],"guid":"ddb6b46c-c6e6-4bf6-86e0-cc20228e6bce","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}}